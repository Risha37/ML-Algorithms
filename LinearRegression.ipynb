{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d14af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDescription\\n----------\\n\\nKey Parameters\\n----------\\n-\\n\\nOptional Parameters\\n----------\\n-\\n\\nReturns\\n----------\\n-\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        \"\"\"\n",
    "        Description\n",
    "        ----------\n",
    "        \n",
    "        Key Parameters\n",
    "        ----------\n",
    "        -\n",
    "        \n",
    "        Optional Parameters\n",
    "        ----------\n",
    "        -\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        -\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faccd867",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "$ Author: Risha $\n",
    "$ https://github.com/Risha37 $\n",
    "$ Revision: 1.0 $\n",
    "\n",
    "TODO\n",
    "- Add Regularizations Terms 'regularization_term'\n",
    "- Add different Gradient Descent Algorithms (Stochastic, Mini-Batch)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class LinearRegression():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Description\n",
    "        ----------\n",
    "        The following are a set of methods intended for regression in which\n",
    "        the target value is expected to be a linear combination of the features.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def fit(self,\n",
    "            X,\n",
    "            y\n",
    "           ):\n",
    "        \"\"\"\n",
    "        Description\n",
    "        ----------\n",
    "        Fits a linear model using the Normal Equation.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        - X : array-like of shape (n_samples, n_features)\n",
    "            Training data\n",
    "            \n",
    "        - y : array-like of shape (n_samples, 1) or (n_samples, n_targets)\n",
    "            Target data\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        - Learned weights : array-like of shape (n_features+1, 1)\n",
    "            Coefficients, Intercept\n",
    "        \"\"\"\n",
    "        #Add ones column vector to represent x_0\n",
    "        X = np.append(X, np.ones((len(X), 1)), axis=1)\n",
    "        return (np.linalg.pinv(X.T @ X) @ (X.T @ y))\n",
    "    \n",
    "    \n",
    "    def predict(self,\n",
    "                X,\n",
    "                optimal_weights\n",
    "               ):\n",
    "        \"\"\"\n",
    "        Description\n",
    "        ----------\n",
    "        Predicts a target given the features value and the learned weights.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        - X : array-like of shape (n_samples, n_features)\n",
    "            Testing data\n",
    "        \n",
    "        - optimal_weight : array-like of shape (n_features+1, 1)\n",
    "            Learned coefficients & intercept after training\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        - y predict (y hat) : array-like of shape (n_samples, 1) or (n_samples, n_targets)\n",
    "            Targets predicted using the 'optimal' weights\n",
    "        \"\"\"\n",
    "        return ((X @ optimal_weights[:-1]) + optimal_weights[-1])\n",
    "    \n",
    "    \n",
    "    def GradientDescent(self,\n",
    "                        X,\n",
    "                        y,\n",
    "                        learning_rate: float=0.1,\n",
    "                        epochs: int=20,\n",
    "                        random_state: int=42,\n",
    "                        initial_weight=None,\n",
    "                        regularization_term=None,\n",
    "                        return_loss: bool=False,\n",
    "                        print_results_epoch=[False, None]\n",
    "                       ):\n",
    "        \"\"\"\n",
    "        Description\n",
    "        ----------\n",
    "        Fits a linear model using the Batch Gradient Descent Algorithm.\n",
    "        \n",
    "        Key Parameters\n",
    "        ----------\n",
    "        - X : array-like of shape (n_samples, n_features)\n",
    "            Training data\n",
    "        \n",
    "        - y : array-like of shape (n_samples, 1) or (n_samples, n_targets)\n",
    "            Target data\n",
    "            \n",
    "        Optional Parameters\n",
    "        ----------\n",
    "        - learning_rate : float, default=0.1\n",
    "            Controls how quickly the model is adapted to the problem (alpha)\n",
    "        \n",
    "        - epochs : int, default=20\n",
    "            The maximum number of passes over the training data\n",
    "            \n",
    "        - random_state : int, default=42\n",
    "            Set random seed to keep consistent results\n",
    "            \n",
    "        - initial_weight : array-like of shape (n_features+1, 1), default=None\n",
    "            [Coefficients, Intercept] Custom initialized weights instead of random initialization.\n",
    "            \n",
    "        - (WIP)regularization_term : {\"Lasso\", \"Ridge\", \"ElasticNet\", None}, default=None\n",
    "            Imposing a penalty on the size of the coefficients to prevent overfitting\n",
    "            \n",
    "        - return_loss : bool, default=False\n",
    "        \n",
    "        - print_results_epoch: list [bool, int], default=None\n",
    "            Print results every n epochs\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        - W : array-like of shape (n_features+1, 1)\n",
    "            Learned Coefficients & Intercept\n",
    "            \n",
    "        - loss : array-like of shape (1, 1), optional\n",
    "            The final loss after n epochs of training\n",
    "        \"\"\"\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "        #Initialise random weights\n",
    "        W = np.random.randn(X.shape[1]+1, 1) if initial_weight is None else initial_weight\n",
    "        \n",
    "        #Add ones column vector to represent x_0\n",
    "        X = np.append(X, np.ones((len(X), 1)), axis=1)\n",
    "        \n",
    "        m = len(X)\n",
    "        for epoch in range(epochs):\n",
    "            if return_loss:\n",
    "                #Vectorized form MSE Cost Function\n",
    "                J = (1/m) * ((X @ W) - y).T @ ((X @ W) - y)\n",
    "            #Vectorized form gradient of the cost function\n",
    "            dJ = (1/m) * (X.T @ (X @ W - y))\n",
    "            \n",
    "            #Gradient Descent step\n",
    "            W = W - learning_rate * dJ\n",
    "            \n",
    "            if print_results_epoch[0]:\n",
    "                if epoch % print_results_epoch[1] == 0 and return_loss:\n",
    "                    print(f\"Epoch: {epoch} | Loss: {J} |\\nWeights: \\n{W}\")\n",
    "                elif epoch % print_results_epoch[1] == 0 and not return_loss:\n",
    "                    print(f\"Epoch: {epoch} |\\nWeights: \\n{W}\")\n",
    "        \n",
    "        return (W) if not return_loss else (W, J)\n",
    "    \n",
    "    \n",
    "    def score(self,\n",
    "              y_true,\n",
    "              y_predict,\n",
    "              criteria: str=\"R2\"\n",
    "             ):\n",
    "        \"\"\"\n",
    "        Description\n",
    "        ----------\n",
    "        (Evaluation metrics) Calculates the {R squared} score.\n",
    "        \n",
    "        Key Parameters\n",
    "        ----------\n",
    "        - y_true: array-like of shape (n_samples,)\n",
    "            The ground truth target data.\n",
    "            \n",
    "        - y_predict: array-like of shape (n_samples,)\n",
    "            The predicted target data.\n",
    "        \n",
    "        Optional Parameters\n",
    "        ----------\n",
    "        - criteria: {\"MSE\", \"RMSE\", \"MAE\", \"R2\"}, default='R2'\n",
    "            The criteria used to evaluate the model.\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        - score: float\n",
    "            The R2 score between y_true and y_predict.\n",
    "        \"\"\"\n",
    "        if criteria == 'R2':\n",
    "            ss_res = np.sum((y_true - y_predict)**2)\n",
    "            ss_tot = np.sum((y_true - np.mean(y_true))**2)\n",
    "            score = 1 - (ss_res / ss_tot)\n",
    "        elif criteria == 'MSE':\n",
    "            score = np.mean((y_true - y_predict)**2)\n",
    "        elif criteria == 'RMSE':\n",
    "            score = np.sqrt(np.mean((y_true - y_predict)**2))\n",
    "        elif criteria == 'MAE':\n",
    "            score = np.mean(np.abs(y_true - y_predict))\n",
    "        \n",
    "            \n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29a5d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataProcessing import DataProcessing\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "data_proc = DataProcessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf5b8714",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "X = np.random.rand(100, 2)\n",
    "y = (7 * X[:, 0] + 3 * X[:, 1] + 9).reshape(-1, 1) + np.random.randn(100, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_proc.train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97f61841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[7.26686784],\n",
       "        [3.43741219],\n",
       "        [8.79540294]]),\n",
       " array([[6.83053296],\n",
       "        [3.50618681],\n",
       "        [8.97732649]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_w0 = lin_reg.fit(X_train, y_train)\n",
    "opt_w1 = lin_reg.GradientDescent(X_train, y_train, epochs=200)\n",
    "\n",
    "opt_w0, opt_w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2702e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred0 = lin_reg.predict(X_test, opt_w0)\n",
    "y_pred1 = lin_reg.predict(X_test, opt_w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb964dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8368500636629697, 0.82840059850818)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score0 = lin_reg.score(y_test, y_pred0)\n",
    "score1 = lin_reg.score(y_test, y_pred1)\n",
    "\n",
    "score0, score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd666b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf66b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fe885c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637f2701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe621f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52fbfc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inspect\n",
    "# print(inspect.getsource())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce634ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
